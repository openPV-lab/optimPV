{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Package Imports #########################################################################\n",
    "import os, warnings, copy, torch, ax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from botorch.acquisition.multi_objective.logei import qLogExpectedHypervolumeImprovement\n",
    "from ax.modelbridge.transforms.standardize_y import StandardizeY\n",
    "from ax.modelbridge.transforms.unit_x import UnitX\n",
    "from ax.modelbridge.transforms.remove_fixed import RemoveFixed\n",
    "from ax.modelbridge.transforms.log import Log\n",
    "from ax.core.base_trial import TrialStatus as T\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "from ax.plot.slice import plot_slice\n",
    "\n",
    "from optimpv import *\n",
    "from optimpv.axBOtorch.axBOtorchOptimizer import axBOtorchOptimizer\n",
    "from optimpv.RateEqfits.RateEqAgent import RateEqAgent\n",
    "from optimpv.RateEqfits.RateEqModel import *\n",
    "from optimpv.RateEqfits.Pumps import *\n",
    "\n",
    "init_notebook_plotting()\n",
    "warnings.filterwarnings('ignore') \n",
    "##############################################################################################\n",
    "# Define the parameters to be fitted\n",
    "params = []\n",
    "\n",
    "k_direct = FitParam(name = 'k_direct', value = 3.9e-17, bounds = [1e-18,1e-16], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$k_{\\text{direct}}$', unit='m$^{3}$ s$^{-1}$', axis_type = 'log', force_log = True)\n",
    "params.append(k_direct)\n",
    "\n",
    "k_trap = FitParam(name = 'k_trap', value = 4e-18, bounds = [1e-19,1e-17], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$k_{\\text{trap}}$', unit='m$^{3}$ s$^{-1}$', axis_type = 'log')\n",
    "params.append(k_trap)\n",
    "\n",
    "k_detrap = FitParam(name = 'k_detrap', value = 3.1e-18, bounds = [1e-19,1e-17], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$k_{\\text{detrap}}$', unit='s$^{-1}$', axis_type = 'log')\n",
    "params.append(k_detrap)\n",
    "\n",
    "N_t_bulk = FitParam(name = 'N_t_bulk', value = 1.6e23, bounds = [1e22,5e23], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$N_{\\text{t,bulk}}$', unit='m$^{-3}$', axis_type = 'log')\n",
    "params.append(N_t_bulk)\n",
    "\n",
    "I_factor = FitParam(name = 'I_factor_PL', value = 1e-32, bounds = [1e-33,1e-31], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$I_{\\text{PL}}$', unit='-', axis_type = 'log')\n",
    "params.append(I_factor)\n",
    "\n",
    "I_factor = FitParam(name = 'I_factor_MC', value = 2.2e-26, bounds = [1e-27,1e-25], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$I_{\\text{PL}}$', unit='-', axis_type = 'log')\n",
    "params.append(I_factor)\n",
    "\n",
    "ratio_mu = FitParam(name = 'ratio_mu', value = 4.2, bounds = [1,10], log_scale = True, rescale = True, value_type = 'float', type='range', display_name=r'$\\mu_{\\text{ratio}}$', unit='-', axis_type = 'linear')\n",
    "params.append(ratio_mu)\n",
    "\n",
    "# original values\n",
    "params_orig = copy.deepcopy(params)\n",
    "dum_dic = {}\n",
    "for i in range(len(params)):\n",
    "    if params[i].force_log:\n",
    "        dum_dic[params[i].name] = np.log10(params[i].value/params[i].fscale)\n",
    "    else:\n",
    "        dum_dic[params[i].name] = params[i].value/params[i].fscale\n",
    "    # dum_dic[params[i].name] = params[i].value/params[i].fscale # we need this just to run the model to generate some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trMC model\n",
    "fpu = 1e3\n",
    "N0 = 1.041e24\n",
    "background = 0\n",
    "\n",
    "t = np.geomspace(5e-8, 1/fpu, 1000)\n",
    "# add 0 to the time array\n",
    "t = np.insert(t, 0, 0)\n",
    "# remove the last element\n",
    "t = t[:-1]\n",
    "# remove t > 1e-4\n",
    "t = t[t<=5e-5]\n",
    "\n",
    "Gfracs = [1, 0.552, 0.290]\n",
    "# concatenate the time and Gfracs\n",
    "X = None\n",
    "for Gfrac in Gfracs:\n",
    "    if X is None:\n",
    "        X = np.array([t,Gfrac*np.ones(len(t))]).T\n",
    "    else:\n",
    "        X = np.concatenate((X,np.array([t,Gfrac*np.ones(len(t))]).T),axis=0) \n",
    "\n",
    "y_ = X # dummy data\n",
    "\n",
    "# Define the agents\n",
    "metric = 'mse'\n",
    "loss = 'soft_l1'\n",
    "threshold = 1\n",
    "exp_format = 'trMC'\n",
    "pump_args = {'N0': N0, 'fpu': fpu , 'background' : background, }\n",
    "\n",
    "RateEq_fake = RateEqAgent(params, [X], [y_], model = BTD_model, pump_model = initial_carrier_density, pump_args = pump_args, fixed_model_args = {}, metric = metric, loss = loss, threshold=threshold,minimize=True,exp_format=exp_format,compare_logs=True,detection_limit=5e-5)\n",
    "\n",
    "y_MC = RateEq_fake.run(dum_dic,exp_format=exp_format)\n",
    "\n",
    "plt.figure()\n",
    "viridis = plt.cm.get_cmap('viridis', len(Gfracs))\n",
    "for idx, Gfrac in enumerate(Gfracs):\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_MC[X[:,1]==Gfrac],'o',label=str(Gfrac), color=viridis(idx))\n",
    "    # plt.plot(t, y_[X[:,1]==Gfrac],label=str(Gfrac)+'_', color=viridis(Gfrac), linestyle='--')\n",
    "# plt.plot(X[:,0], y,'o')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel(exp_format + ' [a.u.]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trPL model\n",
    "metric = 'mse'\n",
    "loss = 'soft_l1'\n",
    "threshold = 1\n",
    "exp_format = 'trPL'\n",
    "\n",
    "pump_args = {'N0': N0, 'fpu': fpu , 'background' : background, }\n",
    "\n",
    "RateEq_fake = RateEqAgent(params, [X], [y_], model = BTD_model, pump_model = initial_carrier_density, pump_args = pump_args, fixed_model_args = {}, metric = metric, loss = loss, threshold=threshold,minimize=True,exp_format=exp_format,compare_logs=True,detection_limit=5e-5)\n",
    "\n",
    "y_PL = RateEq_fake.run(dum_dic,exp_format=exp_format)\n",
    "\n",
    "plt.figure()\n",
    "viridis = plt.cm.get_cmap('viridis', len(Gfracs))\n",
    "for idx, Gfrac in enumerate(Gfracs):\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_PL[X[:,1]==Gfrac],'o',label=str(Gfrac), color=viridis(idx))\n",
    "    # plt.plot(t, y_[X[:,1]==Gfrac],label=str(Gfrac)+'_', color=viridis(Gfrac), linestyle='--')\n",
    "# plt.plot(X[:,0], y,'o')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [s]')\n",
    "# plt.ylim([1e-5,1])\n",
    "plt.ylabel(exp_format + ' [a.u.]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'mse'\n",
    "loss = 'soft_l1'\n",
    "threshold = 1\n",
    "\n",
    "RateEq = RateEqAgent(params, [X,X], [y_PL,y_MC], model = BTD_model, pump_model = initial_carrier_density, pump_args = pump_args, fixed_model_args = {}, metric = [metric,metric], loss = [loss,loss], threshold=[threshold,threshold],minimize=[True,True],exp_format=['trPL','trMC'],compare_logs=True,detection_limit=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model kwargs\n",
    "# from ax.models.torch.botorch_modular.sebo import SEBOAcquisition\n",
    "# # from optimpv.axBOtorch.EGBO import EGBO\n",
    "# from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
    "\n",
    "# from botorch.models import SaasFullyBayesianSingleTaskGP,SingleTaskGP\n",
    "from botorch.acquisition.multi_objective import qNoisyExpectedHypervolumeImprovement\n",
    "# tkwargs = {\n",
    "#     \"dtype\": torch.double,\n",
    "#     \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "# }\n",
    "# aug_dim = len(params)\n",
    "# # target sparse point to regularize towards to. Here we set target sparse value being zero for all the parameters. \n",
    "# target_point = torch.tensor([param.value/3 for param in params], **tkwargs)\n",
    "\n",
    "from testing_notebooks.testEG import EGBOAcquisition\n",
    "\n",
    "model_kwargs_list = [{},{'torch_device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),'torch_dtype': torch.double,'botorch_acqf_class':qNoisyExpectedHypervolumeImprovement,'acquisition_class':EGBOAcquisition,}]\n",
    "model_gen_kwargs_list = [None,None] #'transforms':[RemoveFixed, Log,UnitX, StandardizeY],\n",
    "# 'surrogate':Surrogate(SingleTaskGP),\n",
    "# 'acquisition_class':SEBOAcquisition,\n",
    "# 'acquisition_options':{\n",
    "#             \"penalty\": \"L0_norm\", # it can be L0_norm or L1_norm. \n",
    "#             \"target_point\": target_point, \n",
    "#             \"sparsity_threshold\": aug_dim,\n",
    "#         },\n",
    "#         'torch_device':tkwargs['device'],}]\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = axBOtorchOptimizer(params = params, agents = RateEq, models = ['SOBOL','BOTORCH_MODULAR'],n_batches = [1,40], batch_size = [10,2], ax_client = None,  max_parallelism = -1, model_kwargs_list = model_kwargs_list, model_gen_kwargs_list = model_gen_kwargs_list, name = 'ax_opti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client = optimizer.ax_client\n",
    "pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)\n",
    "best_keys = list(pareto.keys())\n",
    "print(pareto)\n",
    "plt.figure()\n",
    "plt.plot(ax_client.get_trace())\n",
    "\n",
    "#find max in get_trace\n",
    "max_val = np.max(ax_client.get_trace())\n",
    "index_max = np.argmax(ax_client.get_trace())\n",
    "index_max = best_keys[0]\n",
    "best_parameters = pareto[index_max][0]\n",
    "\n",
    "RateEq.params_w(best_parameters,RateEq.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the optimization\n",
    "render(ax_client.get_contour_plot(param_x=\"k_direct\", param_y=\"k_trap\", metric_name=optimizer.all_metrics[0]))\n",
    "\n",
    "model = ax_client.generation_strategy.model\n",
    "\n",
    "render(plot_slice(model=model, param_name=\"k_direct\", metric_name=optimizer.all_metrics[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ax_client.experiment.fetch_data()\n",
    "# split df by metric name \n",
    "data = data.df\n",
    "metric1_df = data[data[\"metric_name\"] == optimizer.all_metrics[0]]\n",
    "metric2_df = data[data[\"metric_name\"] == optimizer.all_metrics[1]]\n",
    "\n",
    "# reset index\n",
    "metric1_df = metric1_df.reset_index(drop=True)\n",
    "metric2_df = metric2_df.reset_index(drop=True)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(np.minimum.accumulate(data.df[\"mean\"]), label=\"Best value seen so far\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.minimum.accumulate(metric1_df[\"mean\"]), label=\"Best value seen so far\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('log of '+optimizer.all_metrics[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.minimum.accumulate(metric2_df[\"mean\"]), label=\"Best value seen so far\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('log of '+optimizer.all_metrics[1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dic with keys same as ax_client.experiment.trials[0].arm.parameters\n",
    "dumdic = {}\n",
    "for key in ax_client.experiment.trials[0].arm.parameters.keys():\n",
    "    dumdic[key] = []\n",
    "\n",
    "# fill the dic with the values of the parameters\n",
    "for i in range(len(ax_client.experiment.trials)):\n",
    "    if ax_client.experiment.trials[i].status == T.COMPLETED:\n",
    "        for key in ax_client.experiment.trials[i].arm.parameters.keys():\n",
    "            dumdic[key].append(ax_client.experiment.trials[i].arm.parameters[key])\n",
    "\n",
    "\n",
    "data = ax_client.experiment.fetch_data().df\n",
    "\n",
    "target1 = data[data['metric_name'] == optimizer.all_metrics[0]]['mean']\n",
    "\n",
    "dumdic[optimizer.all_metrics[0]] = list(target1)\n",
    "\n",
    "target2 = data[data['metric_name'] ==  optimizer.all_metrics[1]]['mean']\n",
    "\n",
    "dumdic[optimizer.all_metrics[1]] = list(target2)\n",
    "\n",
    "dumdic['iteration'] = list(data[data['metric_name'] == optimizer.all_metrics[0]]['trial_index'])\n",
    "\n",
    "df = pd.DataFrame(dumdic)\n",
    "\n",
    "\n",
    "for par in params:\n",
    "    if par.name in df.columns:\n",
    "        if par.rescale:\n",
    "            df[par.name] = df[par.name] * par.fscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get name of all parameters that are not 'fixed'\n",
    "names = []\n",
    "log_scale = []\n",
    "axis_limits = []\n",
    "for p in params:\n",
    "    if p.type != 'fixed':\n",
    "        names.append(p.name)\n",
    "        log_scale.append(p.axis_type == 'log')\n",
    "        axis_limits.append(p.bounds)\n",
    "\n",
    "\n",
    "# Get all combinations of names\n",
    "comb = list(combinations(names, 2))\n",
    "\n",
    "# Determine the grid size\n",
    "n = len(names)\n",
    "fig, axes = plt.subplots(n, n, figsize=(15, 15))\n",
    "\n",
    "# Plot each combination in the grid\n",
    "for i, xx in enumerate(names):\n",
    "    for j, yy in enumerate(names):\n",
    "        xval = np.nan\n",
    "        yval = np.nan\n",
    "\n",
    "        for p in params_orig:\n",
    "            if p.name == xx:\n",
    "                xval = p.value\n",
    "            if p.name == yy:\n",
    "                yval = p.value\n",
    "\n",
    "        ax = axes[i, j]\n",
    "        if i == j:\n",
    "            # kde plot on the diagonal\n",
    "            sns.kdeplot(x=yy, data=df, ax=ax, fill=True, thresh=0, levels=100, cmap=\"rocket\", color=\"#03051A\", log_scale=log_scale[names.index(xx)])\n",
    "\n",
    "            ax.axvline(x=yval, color='r', linestyle='-')\n",
    "            # put point at the best value top of the axis\n",
    "           \n",
    "\n",
    "            if log_scale[names.index(yy)]:\n",
    "                ax.set_xscale('log')\n",
    "                ax.set_xlim(axis_limits[names.index(yy)])\n",
    "            else:\n",
    "                ax.set_xlim(axis_limits[names.index(yy)])\n",
    "            \n",
    "            # put x label on the top\n",
    "            # except for the last one\n",
    "            if i < n - 1:\n",
    "                ax.xaxis.set_label_position('top')\n",
    "                ax.xaxis.tick_top()\n",
    "\n",
    "        elif i > j:\n",
    "            kind = 'kde'\n",
    "            if kind == 'scatter':\n",
    "                sns.scatterplot(x=yy, y=xx, data=df, ax=ax, color=\"#03051A\")\n",
    "                ax.set_xscale('log')\n",
    "                ax.set_yscale('log')\n",
    "            else:\n",
    "                sns.kdeplot(x=yy, y=xx, data=df, ax=ax, fill=True, thresh=0, levels=100, cmap=\"rocket\", color=\"#03051A\", log_scale=(log_scale[names.index(yy)], log_scale[names.index(xx)]))\n",
    "\n",
    "            xval = np.nan\n",
    "            yval = np.nan\n",
    "            for p in params_orig:\n",
    "                if p.name == xx:\n",
    "                    xval = p.value\n",
    "                elif p.name == yy:\n",
    "                    yval = p.value\n",
    "\n",
    "            # Plot as line over the full axis\n",
    "            ax.axhline(y=xval, color='r', linestyle='-')\n",
    "            ax.axvline(x=yval, color='r', linestyle='-')\n",
    "            ax.scatter(best_parameters[yy], best_parameters[xx], c='y', marker='*', s=200, zorder=10)\n",
    "            \n",
    "            ax.set_xlim(axis_limits[names.index(yy)])\n",
    "            ax.set_ylim(axis_limits[names.index(xx)])\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "        if j > 0:\n",
    "            ax.set_yticklabels([])\n",
    "            # remove the y axis label\n",
    "            ax.set_ylabel('')\n",
    "        if i < n - 1:\n",
    "            ax.set_xticklabels([])\n",
    "            # remove the x axis label\n",
    "            ax.set_xlabel('')\n",
    "\n",
    "        if i == n - 1:\n",
    "            ax.set_xlabel(yy)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(xx)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the simulation with the best parameters\n",
    "y_fit_MC = RateEq.run(parameters=best_parameters,exp_format='trMC')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis', 4)\n",
    "for idx, Gfrac in enumerate(Gfracs):\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_fit_MC[X[:,1]==Gfrac],'o',label='fit G='+str(Gfrac),alpha=0.5,color=viridis(idx))\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_MC[X[:,1]==Gfrac],'-',label='data G='+str(Gfrac),color=viridis(idx))\n",
    "    \n",
    "# plt.plot(X[:,0],y,'o',label='data')\n",
    "# plt.plot(X[:,0],yfit,'o',label='fit')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('trMC [a.u.]')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "y_fit_PL = RateEq.run(parameters=best_parameters,exp_format='trPL')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis', 4)\n",
    "for idx, Gfrac in enumerate(Gfracs):\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_fit_PL[X[:,1]==Gfrac],'o',label='fit G='+str(Gfrac),alpha=0.5,color=viridis(idx))\n",
    "    plt.plot(X[X[:,1]==Gfrac,0], y_PL[X[:,1]==Gfrac],'-',label='data G='+str(Gfrac),color=viridis(idx))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('trPL [a.u.]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
