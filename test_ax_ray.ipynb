{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimpv import *\n",
    "from optimpv.axBOtorch.axUtils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "# import logging\n",
    "\n",
    "# from ray import train, tune\n",
    "# from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "# from ray.tune.search.ax import AxSearch\n",
    "\n",
    "\n",
    "init_notebook_plotting()\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ##part of the message is also okay\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "mun = FitParam(name = 'l2.mu_n', value = 3e-5, bounds = [1e-5,1e-3], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\mu_n$', unit='m$^2$ V$^{-1}$s$^{-1}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "mup = FitParam(name = 'l2.mu_p', value = 8e-4, bounds = [1e-5,1e-3], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\mu_p$', unit='m$^2$ V$^{-1}$s$^{-1}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "bulk_tr = FitParam(name = 'l2.N_t_bulk', value = 4e20, bounds = [1e19,1e21], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$N_{T}$', unit='s', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# W_L = FitParam(name = 'W_L', value = 4.05, bounds = [3.92,4.1], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$W_L$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# C_np_bulk = FitParam(name = 'l2.C_np_bulk', value = 1e-13, bounds = [1e-14,1e-12], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = True, stepsize = None, display_name=r'$C_{np}$', unit='m$^{-3}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_l2_l1 = FitParam(name = 'offset_l2_l1.E_c', value = -0.1, bounds = [-0.2,0.0], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L2-L1}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# offset_l3_l2 = FitParam(name = 'offset_l3_l2.E_c', value = -1.65, bounds = [-2,0], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L3-L2}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_l2_l3 = FitParam(name = 'offset_l2_l3.E_v', value = 0.1, bounds = [0,0.3], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L2-L3}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "Egap_l1 = FitParam(name = 'Egap_l1.E_v', value = 1.6, bounds = [1.55,1.65], type='fixed', values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$E_{gap,L1}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_W_L = FitParam(name = 'offset_W_L.E_c', value = -0.1, bounds = [-0.2,0], type='fixed', values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta W_L$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "params = [mun, mup, bulk_tr, offset_l2_l1, offset_l2_l3, Egap_l1, offset_W_L]\n",
    "\n",
    "# ({'l2.mu_n': 0.001, 'l2.mu_p': 1e-05, 'l2.N_t_bulk': 1.7603940470752775e+20, 'l2.C_np_bulk': 2.737249616717965, 'offset_l2_l1.E_c': -0.07161177367482424, 'offset_l2_l3.E_v': 0.18380439095587323, 'Egap_l1.E_v': 1.6, 'offset_W_L.E_c': -0.1}, ({'rmsre': np.float64(-0.22903756081756554)}, {'rmsre': {'rmsre': np.float64(0.0016075557479600649)}}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimpv import *\n",
    "from optimpv.axBOtorch.axUtils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "# import logging\n",
    "\n",
    "# from ray import train, tune\n",
    "# from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "# from ray.tune.search.ax import AxSearch\n",
    "\n",
    "\n",
    "init_notebook_plotting()\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ##part of the message is also okay\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "mun = FitParam(name = 'l2.mu_n', value = 3e-5, bounds = [1e-5,1e-3], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\mu_n$', unit='m$^2$ V$^{-1}$s$^{-1}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "mup = FitParam(name = 'l2.mu_p', value = 8e-4, bounds = [1e-5,1e-3], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\mu_p$', unit='m$^2$ V$^{-1}$s$^{-1}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "bulk_tr = FitParam(name = 'l2.N_t_bulk', value = 4e20, bounds = [1e19,1e21], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$N_{T}$', unit='s', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# W_L = FitParam(name = 'W_L', value = 4.05, bounds = [3.92,4.1], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$W_L$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# C_np_bulk = FitParam(name = 'l2.C_np_bulk', value = 1e-13, bounds = [1e-14,1e-12], values = None, start_value = None, log_scale = True, value_type = 'float', fscale = None, rescale = True, stepsize = None, display_name=r'$C_{np}$', unit='m$^{-3}$', axis_type = 'log', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_l2_l1 = FitParam(name = 'offset_l2_l1.E_c', value = -0.1, bounds = [-0.2,0.0], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L2-L1}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "# offset_l3_l2 = FitParam(name = 'offset_l3_l2.E_c', value = -1.65, bounds = [-2,0], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L3-L2}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_l2_l3 = FitParam(name = 'offset_l2_l3.E_v', value = 0.1, bounds = [0,0.3], values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta E_{L2-L3}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "Egap_l1 = FitParam(name = 'Egap_l1.E_v', value = 1.6, bounds = [1.55,1.65], type='fixed', values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$E_{gap,L1}$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "offset_W_L = FitParam(name = 'offset_W_L.E_c', value = -0.1, bounds = [-0.2,0], type='fixed', values = None, start_value = None, log_scale = False, value_type = 'float', fscale = None, rescale = False, stepsize = None, display_name=r'$\\Delta W_L$', unit='eV', axis_type = 'linear', std = 0,encoding = None,force_log = False)\n",
    "\n",
    "params = [mun, mup, bulk_tr, offset_l2_l1, offset_l2_l3, Egap_l1, offset_W_L]\n",
    "\n",
    "# ({'l2.mu_n': 0.001, 'l2.mu_p': 1e-05, 'l2.N_t_bulk': 1.7603940470752775e+20, 'l2.C_np_bulk': 2.737249616717965, 'offset_l2_l1.E_c': -0.07161177367482424, 'offset_l2_l3.E_v': 0.18380439095587323, 'Egap_l1.E_v': 1.6, 'offset_W_L.E_c': -0.1}, ({'rmsre': np.float64(-0.22903756081756554)}, {'rmsre': {'rmsre': np.float64(0.0016075557479600649)}}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pySIMsalabim as sim\n",
    "from pySIMsalabim.experiments.JV_steady_state import *\n",
    "\n",
    "session_path = os.path.join('/home/lecorre/Desktop/pySIMsalabim/', 'SIMsalabim','SimSS')\n",
    "simss_device_parameters = os.path.join(session_path, 'simulation_setup.txt')\n",
    "\n",
    "# Set the JV parameters\n",
    "Gfracs = [0.1,0.5,1.0] # Fractions of the generation rate to simulate\n",
    "# Gfracs = None\n",
    "UUID = str(uuid.uuid4())\n",
    "\n",
    "cmd_pars = []\n",
    "for param in params:\n",
    "    if param.name != 'l2.C_np_bulk' and param.name != 'offset_l2_l1.E_c' and param.name != 'offset_l2_l3.E_v' and param.name != 'Egap_l1.E_v' and param.name != 'offset_W_L.E_c':\n",
    "        cmd_pars.append({'par':param.name, 'val':str(param.value)})\n",
    "    elif param.name == 'offset_l2_l1.E_c':\n",
    "        cmd_pars.append({'par':'l1.E_c', 'val':str(3.9-param.value)})\n",
    "        vv = 3.9-param.value\n",
    "  \n",
    "    elif param.name == 'l2.C_np_bulk':\n",
    "        cmd_pars.append({'par':'l2.C_n_bulk', 'val':str(param.value)})\n",
    "        cmd_pars.append({'par':'l2.C_p_bulk', 'val':str(param.value)})\n",
    "\n",
    "    elif param.name == 'offset_l2_l3.E_v':\n",
    "        cmd_pars.append({'par':'l3.E_v', 'val':str(5.53-param.value)})\n",
    "    \n",
    "    elif param.name == 'Egap_l1.E_v':\n",
    "        cmd_pars.append({'par':'l1.E_v', 'val': str(vv+param.value)})\n",
    "    \n",
    "    elif param.name == 'offset_W_L.E_c':\n",
    "        cmd_pars.append({'par':'W_L', 'val':str(vv-param.value)})\n",
    "\n",
    "\n",
    "print(cmd_pars)\n",
    "\n",
    "# Run the JV simulation\n",
    "ret, mess = run_SS_JV(simss_device_parameters, session_path, JV_file_name = 'JV.dat', varFile= 'Var.dat',G_fracs = Gfracs, parallel = True, max_jobs = 3, UUID=UUID, cmd_pars=cmd_pars)\n",
    "\n",
    "\n",
    "# save data for fitting\n",
    "X,y = [],[]\n",
    "if Gfracs is None:\n",
    "    data = pd.read_csv(os.path.join(session_path, 'JV_'+UUID+'.dat'), sep=r'\\s+') # Load the data\n",
    "    Vext = np.asarray(data['Vext'].values)\n",
    "    Jext = np.asarray(data['Jext'].values)\n",
    "    G = np.ones_like(Vext)\n",
    "\n",
    "    X= Vext\n",
    "    y = Jext\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X,y)\n",
    "    plt.show()\n",
    "else:\n",
    "    for Gfrac in Gfracs:\n",
    "        data = pd.read_csv(os.path.join(session_path, 'JV_Gfrac_'+str(Gfrac)+'_'+UUID+'.dat'), sep=r'\\s+') # Load the data\n",
    "        Vext = np.asarray(data['Vext'].values)\n",
    "        Jext = np.asarray(data['Jext'].values)\n",
    "        G = np.ones_like(Vext)*Gfrac\n",
    "\n",
    "        if len(X) == 0:\n",
    "            X = np.vstack((Vext,G)).T\n",
    "            y = Jext\n",
    "        else:\n",
    "            X = np.vstack((X,np.vstack((Vext,G)).T))\n",
    "            y = np.hstack((y,Jext))\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    for Gfrac in Gfracs:\n",
    "        plt.plot(X[X[:,1]==Gfrac,0],y[X[:,1]==Gfrac],label='Gfrac = '+str(Gfrac))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimpv.DDfits.JVAgent import JVAgent\n",
    "metric = 'rmsre'\n",
    "# metric = 'mse'\n",
    "loss = 'log10'\n",
    "# loss = 'linear'\n",
    "\n",
    "jv = JVAgent(params, X, y, session_path, simss_device_parameters,parallel = True, max_jobs = 3, metric = metric, loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jv.SIMsalabim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jv.run(parameters={mun.name: 3e-4, mup.name: 6e-4})\n",
    "# jv.run_Ax(parameters={mun.name: -4, mup.name: -4, bulk_tr.name: 20, C_np_bulk.name: -13, offset_l2_l1.name: -0.1, offset_l2_l3.name: 0.13, Egap_l1.name: 1.6, offset_W_L.name: -0.1 },)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_space = ConvertParamsAx(params)\n",
    "print(parameters_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax import *\n",
    "\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "# steps = [GenerationStep(\n",
    "#     model=Models.SOBOL,\n",
    "#     num_trials=10,\n",
    "#     max_parallelism=10,\n",
    "# ),GenerationStep(\n",
    "#     model=Models.GPEI,\n",
    "#     num_trials=50,\n",
    "#     min_trials_observed=4,\n",
    "#     max_parallelism=4,\n",
    "#     model_kwargs= {\"torch_device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\"torch_dtype\": torch.double},#,\"num_samples\": 128,\"warmup_steps\": 256},\n",
    "#     # model_gen_kwargs={\"num_samples\": 100,\"warmup_steps\": 200}\n",
    "# )]\n",
    "# generation_strategy = GenerationStrategy(steps=steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple, Type\n",
    "\n",
    "from ax.modelbridge.registry import Models\n",
    "\n",
    "# Ax data tranformation layer\n",
    "from ax.models.torch.botorch_modular.acquisition import Acquisition\n",
    "\n",
    "# Ax wrappers for BoTorch components\n",
    "from ax.models.torch.botorch_modular.model import BoTorchModel\n",
    "from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
    "\n",
    "# Experiment examination utilities\n",
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "# Test Ax objects\n",
    "from ax.utils.testing.core_stubs import (\n",
    "    get_branin_data,\n",
    "    get_branin_data_multi_objective,\n",
    "    get_branin_experiment,\n",
    "    get_branin_experiment_with_multi_objective,\n",
    ")\n",
    "from botorch.acquisition.logei import (\n",
    "    qLogExpectedImprovement,\n",
    "    qLogNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "\n",
    "# BoTorch components\n",
    "from botorch.models.model import Model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "# warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "# warnings.simplefilter(action='ignore', category=NumericalWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "# steps = [GenerationStep(\n",
    "#     model=Models.SOBOL,\n",
    "#     num_trials=10,\n",
    "#     max_parallelism=10,\n",
    "# ),GenerationStep(\n",
    "#     model=Models.GPEI,\n",
    "#     num_trials=300,\n",
    "#     min_trials_observed=4,\n",
    "#     max_parallelism=4,\n",
    "#     model_kwargs= {\"torch_device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\"torch_dtype\": torch.double,},#,\"num_samples\": 128,\"warmup_steps\": 256},\n",
    "#     # model_gen_kwargs={\"num_samples\": 100,\"warmup_steps\": 200}\n",
    "# )]\n",
    "\n",
    "# ax_client = AxClient(generation_strategy=generation_strategy)\n",
    "\n",
    "from ax.modelbridge.transforms.standardize_y import StandardizeY\n",
    "from ax.modelbridge.transforms.unit_x import UnitX\n",
    "from ax.modelbridge.transforms.remove_fixed import RemoveFixed\n",
    "from ax.modelbridge.transforms.log import Log\n",
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        # 1. Initialization step (does not require pre-existing data and is well-suited for\n",
    "        # initial sampling of the search space)\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL,\n",
    "            num_trials=5,  # How many trials should be produced from this generation step\n",
    "            min_trials_observed=3,  # How many trials need to be completed to move to next model\n",
    "            max_parallelism=4,  # Max parallelism for this step\n",
    "            model_kwargs={\"seed\": 999},  # Any kwargs you want passed into the model\n",
    "            model_gen_kwargs={},  # Any kwargs you want passed to `modelbridge.gen`\n",
    "        ),\n",
    "        # 2. Bayesian optimization step (requires data obtained from previous phase and learns\n",
    "        # from all data available at the time of each new candidate generation call)\n",
    "        GenerationStep(\n",
    "            model=Models.BOTORCH_MODULAR,\n",
    "            num_trials=-1,  # No limitation on how many trials should be produced from this step\n",
    "            max_parallelism=4,  # Parallelism limit for this step, often lower than for Sobol\n",
    "            model_kwargs= {\"torch_device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\"torch_dtype\": torch.double,\"botorch_acqf_class\":qLogNoisyExpectedImprovement,\"transforms\":[RemoveFixed, Log,UnitX, StandardizeY]},  # Any kwargs you want passed into the model [RemoveFixed,UnitX, StandardizeY]\n",
    "                           \n",
    "            model_gen_kwargs= {'n': 1},  # Any kwargs you want passed to `modelbridge.gen`\n",
    "            # More on parallelism vs. required samples in BayesOpt:\n",
    "            # https://ax.dev/docs/bayesopt.html#tradeoff-between-parallelism-and-total-number-of-trials\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ax_client = AxClient(generation_strategy=gs)\n",
    "ax_client.create_experiment(\n",
    "    name=\"test\",\n",
    "    parameters=parameters_space,\n",
    "    objectives={metric:ObjectiveProperties(minimize=True)},\n",
    "    outcome_constraints=None,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "batch_size = 2\n",
    "num_trials = 220\n",
    "for i in range(int(num_trials//batch_size)):\n",
    "    parameters, trial_index = ax_client.get_next_trials(batch_size)\n",
    "\n",
    "    results = Parallel(n_jobs=batch_size)(delayed(jv.run_Ax)(p) for p in parameters.values())\n",
    "\n",
    "    for trial_index, raw_data in zip(parameters.keys(), results):\n",
    "        # print(np.isnan(raw_data[metric]))\n",
    "        if not np.isnan(raw_data[metric]):\n",
    "            ax_client.complete_trial(trial_index=trial_index, raw_data=raw_data)\n",
    "        else:\n",
    "            ax_client.log_trial_failure(trial_index=trial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best parameters\n",
    "best_parameters = ax_client.get_best_parameters()\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_parameters[0])\n",
    "jv.params_w(best_parameters[0],jv.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jv.get_SIMsalabim_clean_cmd(best_parameters[0]))\n",
    "print(jv.get_SIMsalabim_clean_cmd(jv.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jv.package_SIMsalabim_files(jv.params,'simss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = AxClient(enforce_sequential_optimization=False, generation_strategy = generation_strategy)\n",
    "# MINIMIZE = False  # Whether we should be minimizing or maximizing the objective\n",
    "# # name=\"JV_fit\",\n",
    "# # parameters=[\n",
    "# #     {\"name\": mun.name, \"type\": \"range\", \"bounds\": mun.bounds, \"log_scale\": mun.log_scale},\n",
    "# #     {\"name\": mup.name, \"type\": \"range\", \"bounds\": mup.bounds, \"log_scale\": mup.log_scale},]\n",
    "# ax.create_experiment(\n",
    "#     name=\"JV_fit\",\n",
    "#     parameters=parameters_space,\n",
    "#     objective_name=metric,\n",
    "#     minimize=MINIMIZE,\n",
    "# )\n",
    "# logger = logging.getLogger(tune.__name__)\n",
    "# logger.setLevel(\n",
    "#     level=logging.CRITICAL\n",
    "# )  # Reduce the number of Ray warnings that are not relevant here.\n",
    "# # Set up AxSearcher in RayTune\n",
    "# algo = AxSearch( ax_client=ax)\n",
    "# # Wrap AxSearcher in a concurrently limiter, to ensure that Bayesian optimization receives the\n",
    "# # data for completed trials before creating more trials\n",
    "# algo = tune.search.ConcurrencyLimiter(algo, max_concurrent=10)\n",
    "# tuner = tune.Tuner(\n",
    "#     jv.run_Ax,\n",
    "#     run_config=train.RunConfig(\n",
    "#             name=\"ax\",\n",
    "#         ),\n",
    "#     tune_config=tune.TuneConfig(\n",
    "#         metric = metric,\n",
    "#         mode = 'min',\n",
    "#         search_alg=algo,\n",
    "#         scheduler=AsyncHyperBandScheduler(),\n",
    "#         num_samples=310,\n",
    "#     ),\n",
    "#     # param_space = {\n",
    "#     #     # loguniform distribution between 1e-4 and 1e-3\n",
    "#     #     mun.name: tune.loguniform(1e-4, 1e-3),\n",
    "#     #     mup.name: tune.loguniform(1e-4, 1e-3),\n",
    "#     # },\n",
    "# )\n",
    "\n",
    "# # Run the optimization\n",
    "# results = tuner.fit()\n",
    "\n",
    "# print(\"Best hyperparameters found were: \", results.get_best_result(metric=metric,mode='min',filter_nan_and_inf=True).config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the optimization\n",
    "render(ax_client.get_contour_plot(param_x=\"l2.mu_n\", param_y=\"l2.mu_p\", metric_name=metric))\n",
    "# render(ax_client.get_contour_plot(param_x=\"l2.N_t_bulk\", param_y=\"l2.C_np_bulk\", metric_name=metric))\n",
    "from ax.plot.slice import plot_slice\n",
    "model = ax_client.generation_strategy.model\n",
    "\n",
    "render(plot_slice(model=model, param_name=\"l2.mu_n\", metric_name=metric))\n",
    "render(plot_slice(model=model, param_name=\"l2.mu_p\", metric_name=metric))\n",
    "render(plot_slice(model=model, param_name=\"l2.N_t_bulk\", metric_name=metric))\n",
    "# render(plot_slice(model=model, param_name=\"l2.C_np_bulk\", metric_name=metric))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ax_client.experiment.fetch_data()\n",
    "\n",
    "plt.plot(np.minimum.accumulate(data.df[\"mean\"]), label=\"Best value seen so far\")\n",
    "\n",
    "# plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mun = []\n",
    "mup = []\n",
    "mse = []\n",
    "# create dic with keys same as ax_client.experiment.trials[0].arm.parameters\n",
    "dumdic = {}\n",
    "for key in ax_client.experiment.trials[0].arm.parameters.keys():\n",
    "    dumdic[key] = []\n",
    "from ax.core.base_trial import TrialStatus as T\n",
    "# fill the dic with the values of the parameters\n",
    "for i in range(len(ax_client.experiment.trials)):\n",
    "    if ax_client.experiment.trials[i].status == T.COMPLETED:\n",
    "        for key in ax_client.experiment.trials[i].arm.parameters.keys():\n",
    "            dumdic[key].append(ax_client.experiment.trials[i].arm.parameters[key])\n",
    "\n",
    "\n",
    "from ax.core.base_trial import TrialStatus as T\n",
    "for i in range(len(ax_client.experiment.trials)):\n",
    "    if ax_client.experiment.trials[i].status == T.COMPLETED:\n",
    "        mun.append(ax_client.experiment.trials[i].arm.parameters['l2.mu_n'])\n",
    "        mup.append(ax_client.experiment.trials[i].arm.parameters['l2.mu_p'])\n",
    "\n",
    "data = ax_client.experiment.fetch_data().df\n",
    "# print(data)\n",
    "mse = data['mean']\n",
    "dumdic['mse'] = mse\n",
    "\n",
    "# remove the last value in mun and mup\n",
    "# mun = mun[:-1]\n",
    "# mup = mup[:-1]\n",
    "interation = np.arange(len(mun))\n",
    "plt.figure()\n",
    "# plt.tricontourf(mun,mup,mse)\n",
    "plt.scatter(mun,mup,c=interation)\n",
    "plt.colorbar()\n",
    "plt.scatter(3e-4,8e-4,c='r')\n",
    "# plt.scatter(np.log10(3e-4),np.log10(8e-4),c='r')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.tricontourf(mun,mup,mse)\n",
    "# plt.scatter(mun,mup,c=mse)\n",
    "plt.colorbar()\n",
    "plt.scatter(3e-4,8e-4,c='r')\n",
    "plt.scatter(np.log10(3e-4),np.log10(8e-4),c='r')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters[0]['l2.mu_n']\n",
    "best_parameters[0]['l2.mu_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot density of the optimization\n",
    "import seaborn as sns\n",
    "plt.figure()\n",
    "# df = pd.DataFrame({'l2.mu_n':mun,'l2.mu_p':mup,'mse':mse})\n",
    "df =pd.DataFrame(dumdic)\n",
    "# sort df by mse\n",
    "df = df.sort_values(by='mse')\n",
    "\n",
    "g = sns.jointplot(x='l2.mu_n',y='l2.mu_p',data=df,kind='kde',fill=True,thresh=0, levels=100, cmap=\"rocket\",color=\"#03051A\",space=0, marginal_ticks=False,log_scale=(True,True))\n",
    "\n",
    "plt.scatter(3e-5,8e-4,c='r')\n",
    "plt.scatter(best_parameters[0]['l2.mu_n'],best_parameters[0]['l2.mu_p'],c='y',marker='*',s=200)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# df = pd.DataFrame({'l2.mu_n':mun,'l2.mu_p':mup,'mse':mse})\n",
    "df =pd.DataFrame(dumdic)\n",
    "# sort df by mse\n",
    "df = df.sort_values(by='mse')\n",
    "xx = 'l2.N_t_bulk'\n",
    "yy = 'offset_l2_l1.E_c'\n",
    "kind = 'kde'\n",
    "if kind == 'scatter':\n",
    "    g = sns.jointplot(x=xx,y=yy,data=df,kind=kind, cmap=\"rocket\",color=\"#03051A\",space=0, marginal_ticks=False)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    g = sns.jointplot(x=xx,y=yy,data=df,kind=kind,fill=True, thresh=0, levels = 100, cmap=\"rocket\",color=\"#03051A\",space=0, marginal_ticks=False,log_scale=(True,False))\n",
    "# plt.scatter(3e-5,8e-4,c='r')\n",
    "plt.scatter(best_parameters[0][xx],best_parameters[0][yy],c='y',marker='*',s=200)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best fit\n",
    "# px = [] \n",
    "# for par in params:\n",
    "#     px.append(results.get_best_result(metric=metric,mode='min',filter_nan_and_inf=True).config[par.name])\n",
    "# print(px)\n",
    "\n",
    "yfit = jv.run(parameters=ax_client.get_best_parameters()[0])\n",
    "# print(jv.run_Ax(parameters=results.get_best_result(metric=metric,mode='min',filter_nan_and_inf=True).config))\n",
    "plt.figure(figsize=(20,20))\n",
    "for Gfrac in Gfracs:\n",
    "    plt.plot(X[X[:,1]==Gfrac,0],y[X[:,1]==Gfrac],label='Gfrac = '+str(Gfrac))\n",
    "    plt.plot(X[X[:,1]==Gfrac,0],yfit[X[:,1]==Gfrac],label='Gfrac = '+str(Gfrac)+' fit',linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray import tune\n",
    "# from ray.tune.search.hebo import HEBOSearch\n",
    "\n",
    "# config = {\n",
    "#     mun.name: tune.loguniform(1e-4, 1e-3),\n",
    "#     mup.name: tune.loguniform(1e-4, 1e-3),\n",
    "# }\n",
    "\n",
    "# hebo = HEBOSearch(metric='mse', mode='min') \n",
    "# tuner = tune.Tuner(\n",
    "#     jv.run_Ax,\n",
    "#     tune_config=tune.TuneConfig(\n",
    "#         search_alg=hebo,\n",
    "#         num_samples=80,\n",
    "#     ),\n",
    "#     param_space=config,\n",
    "#     # tune_config=tune.TuneConfig(num_samples=20)\n",
    "\n",
    "# )\n",
    "\n",
    "# results = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best hyperparameters found were: \", results.get_best_result(metric='mse',mode='min').config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the output files (comment out if you want to keep the output files)\n",
    "sim.clean_all_output(session_path)\n",
    "sim.delete_folders('tmp',session_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
